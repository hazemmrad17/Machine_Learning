{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMa72yDd4bOj"
   },
   "source": [
    "# Breast Cancer Detection\n",
    "\n",
    "This notebook investigates automatic breast cancer detection using classical machine learning models and a GRU–SVM hybrid on the Wisconsin Diagnostic Breast Cancer dataset. We follow a full experimental pipeline: exploratory data analysis, careful data preparation, hyperparameter tuning, evaluation on a held-out test set, and learning-curve analysis to support the paper’s conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vN6d5bS4bpI"
   },
   "outputs": [],
   "source": [
    "# Imports des bibliothèques principales pour la manipulation de données et la visualisation\n",
    "import pandas as pd        # pd : alias standard pour la bibliothèque pandas (tableaux de données type DataFrame)\n",
    "import numpy as np         # np : alias standard pour NumPy (calcul numérique, tableaux n-dimensionnels)\n",
    "import matplotlib.pyplot as plt  # plt : interface de tracé principale de Matplotlib\n",
    "import seaborn as sns      # sns : bibliothèque de visualisation de haut niveau, basée sur Matplotlib\n",
    "\n",
    "# Outils de scikit-learn pour découper les données en ensembles d'entraînement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Outils de prétraitement : standardisation des features et encodage des labels catégoriels\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Modèles linéaires et de type SGD (descente de gradient stochastique)\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression\n",
    "\n",
    "# Support Vector Machines (SVM) pour la classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Réseaux de neurones de type perceptron multicouche (MLP)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Méthode des k plus proches voisins (k-NN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Métriques d'évaluation classiques pour la classification et la régression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,   # matrice de confusion (TP, TN, FP, FN)\n",
    "    roc_auc_score,      # aire sous la courbe ROC\n",
    "    roc_curve,          # points de la courbe ROC (TPR/FPR)\n",
    "    accuracy_score,     # proportion de prédictions correctes\n",
    "    recall_score,       # rappel (sensibilité) : proportion de positifs bien détectés\n",
    "    precision_score,    # précision : proportion de prédictions positives correctes\n",
    "    f1_score,           # F1-score : moyenne harmonique précision / rappel\n",
    "    mean_squared_error  # erreur quadratique moyenne (utile pour la régression)\n",
    ")\n",
    "\n",
    "# Composants Keras/TensorFlow pour le modèle GRU–SVM\n",
    "from tensorflow.keras.models import Sequential           # modèle séquentiel (empilement de couches)\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Input  # couches GRU, denses, dropout et entrée explicite\n",
    "from tensorflow.keras.callbacks import EarlyStopping      # callback pour arrêter l'entraînement si la val_loss ne s'améliore plus\n",
    "from tensorflow.keras.optimizers import Adam              # optimiseur Adam (descente de gradient adaptative)\n",
    "from tensorflow.keras.layers import BatchNormalization    # normalisation de batch pour stabiliser l'entraînement\n",
    "\n",
    "# Style global des graphiques Seaborn (fond blanc quadrillé pour une meilleure lisibilité)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "R-Fgvyn64dvs",
    "outputId": "90926e2e-9921-4bf0-fc98-409f4286b969"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C05zQyi_4fke",
    "outputId": "ec8aee63-b286-4f58-b3e2-f6f022035dc5"
   },
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {df.shape[1] - 1}\")\n",
    "print(f\"Samples: {df.shape[0]}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_YCWbMw4hMj"
   },
   "source": [
    "# 1. Dataset Overview\n",
    "\n",
    "We first inspect the raw dataset to understand its size, feature set, and basic data types. These descriptive statistics ensure the input is well-formed and provide context (number of patients and features) for the subsequent preprocessing and modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ub_ZbEjd4izx",
    "outputId": "1bc2f72d-e1db-4eb8-a655-e27a39b5a2bc"
   },
   "outputs": [],
   "source": [
    "missing_count = df.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "qYAXClr_4kOU",
    "outputId": "97fa254d-c4aa-49f3-d5cc-56f838e827b2"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr2MbGH64nBh"
   },
   "source": [
    "# 2. Feature Structure\n",
    "\n",
    "Here we examine the distribution of the target variable (`diagnosis`) and quantify the imbalance between benign and malignant cases. The bar plot and class counts show that benign tumors are more frequent, motivating the later use of SMOTE to balance the training data for fair model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "diagnosis_counts = df['diagnosis'].value_counts()\n",
    "sns.countplot(x='diagnosis', data=df, hue='diagnosis', legend=False)\n",
    "plt.title('Diagnosis Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Class distribution:\\n{diagnosis_counts}\")\n",
    "print(f\"Imbalance ratio: {diagnosis_counts['B'] / diagnosis_counts['M']:.2f}:1 (Benign:Malignant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLPQz-JF4qdb"
   },
   "source": [
    "# 3. Data Visualization\n",
    "\n",
    "We visualize missing values and feature distributions to detect potential quality issues and outliers. The null-value heatmap confirms that the only fully missing column is `Unnamed: 32`, while the per-feature boxplots reveal the range and skewness of each measurement, supporting the decision to standardize features before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Null Values Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Samples')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total missing values: {df.isnull().sum().sum()}\")\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6EJ1yNBX4rW6",
    "outputId": "e60f9784-4278-46ce-c327-0cbda23df50c"
   },
   "outputs": [],
   "source": [
    "if 'numeric_cols' not in locals():\n",
    "    numeric_cols = [col for col in df.columns if col not in ['id', 'Unnamed: 32', 'diagnosis']]\n",
    "\n",
    "n_features = len(numeric_cols)\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(n_cols * 5, n_rows * 4))\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "    sns.boxplot(y=df[col], ax=ax)\n",
    "    ax.set_title(f'Distribution de {col}', fontsize=10)\n",
    "    ax.set_ylabel('')\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko831fnd4s8j"
   },
   "source": [
    "# 4. Correlation Analysis\n",
    "\n",
    "We compute a correlation matrix between all numeric predictors and the encoded target (`diagnosis_encoded`). The resulting heatmap highlights groups of highly correlated features (e.g., perimeter/area measures) and shows which measurements are most associated with malignancy, guiding later feature reduction and interpretation of model behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "id": "Z_mF3umn4uBw",
    "outputId": "add78799-78af-4f59-c855-b7442f6e0c99"
   },
   "outputs": [],
   "source": [
    "numeric_cols = [col for col in df.columns if col not in ['id', 'Unnamed: 32', 'diagnosis']]\n",
    "\n",
    "df_encoded = df.copy()\n",
    "df_encoded['diagnosis_encoded'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "corr_cols = numeric_cols + ['diagnosis_encoded']\n",
    "corr_matrix = df_encoded[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 18))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    "    vmin=-1, vmax=1,\n",
    "    annot_kws={'size': 6},\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title('Feature and Target Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"High correlations indicate related features. This is expected as features are derived from the same base measurements.\")\n",
    "print(\"The last row/column shows correlations between features and the target (diagnosis_encoded).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcGelrg84vzB"
   },
   "source": [
    "# 5. Data Preparation\n",
    "\n",
    "In this step we clean and transform the data before modeling. We drop non-informative and highly redundant columns, encode the target label, stratify the train/test split, standardize all features, and apply SMOTE **only** on the training data to rebalance classes. This pipeline prevents test leakage and ensures that the performance metrics reported later reflect generalization to unseen patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERHJflEV4xTf",
    "outputId": "1a785131-75be-4e01-a9c2-3d35e326471e"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# Préparation et découpage du jeu de données\n",
    "# =====================================================================\n",
    "\n",
    "import numpy as np  # utilisé ici pour compter les exemples par classe avec np.bincount\n",
    "from sklearn.model_selection import train_test_split  # fonction pour diviser le jeu de données\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # encodage des labels et standardisation des features\n",
    "from imblearn.over_sampling import SMOTE  # SMOTE : sur-échantillonnage synthétique des minoritaires\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Nettoyage des colonnes non pertinentes ou fortement redondantes\n",
    "# ---------------------------------------------------------------------\n",
    "# La colonne 'id' est un identifiant unique sans valeur prédictive directe.\n",
    "# 'Unnamed: 32' est entièrement vide dans ce jeu de données.\n",
    "# Les colonnes de périmètre/surface très corrélées sont retirées pour réduire la redondance\n",
    "# et limiter le risque de sur-apprentissage tout en simplifiant les modèles.\n",
    "df = df.drop([\n",
    "    'id',             # identifiant inutile pour la prédiction\n",
    "    'Unnamed: 32',    # colonne vide\n",
    "    'perimeter_mean', # fortement corrélée avec radius/area\n",
    "    'perimeter_se',\n",
    "    'radius_worst',\n",
    "    'area_mean',\n",
    "    'perimeter_worst',\n",
    "    'area_se',\n",
    "    'area_worst'\n",
    "], axis=1, errors='ignore')  # errors='ignore' : ne pas lever d'erreur si une colonne n'existe pas\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Encodage de la variable cible (diagnosis) en 0/1\n",
    "# ---------------------------------------------------------------------\n",
    "le = LabelEncoder()                     # instancie un encodeur pour transformer les labels catégoriels en entiers\n",
    "# 'M' (malignant) et 'B' (benign) deviennent typiquement 1 et 0\n",
    "# fit_transform apprend le mapping puis applique la transformation sur la colonne 'diagnosis'\n",
    "df['diagnosis'] = le.fit_transform(df['diagnosis'])\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Séparation features / cible\n",
    "# ---------------------------------------------------------------------\n",
    "X = df.drop('diagnosis', axis=1)  # X : toutes les colonnes sauf la cible\n",
    "y = df['diagnosis']               # y : variable cible binaire (0 = bénin, 1 = malin)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Split entraînement / test (avec stratification)\n",
    "# ---------------------------------------------------------------------\n",
    "# test_size=0.3 : 30 % des données pour le test, 70 % pour l'entraînement\n",
    "# random_state=42 : graine fixe pour rendre le split reproductible\n",
    "# stratify=y : conserve le même ratio de classes (0/1) dans train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Affichage de la taille des ensembles pour vérifier le split\n",
    "print(f\"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Distribution des classes AVANT SMOTE (important pour justifier le rééquilibrage)\n",
    "print(\"\\nTrain class distribution (before SMOTE):\")\n",
    "print(f\"  Benign (0): {np.bincount(y_train)[0]}\")   # nombre de cas bénins dans l'entraînement\n",
    "print(f\"  Malignant (1): {np.bincount(y_train)[1]}\")  # nombre de cas malins\n",
    "\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(f\"  Benign (0): {np.bincount(y_test)[0]}\")\n",
    "print(f\"  Malignant (1): {np.bincount(y_test)[1]}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) Standardisation des caractéristiques\n",
    "# ---------------------------------------------------------------------\n",
    "# StandardScaler met chaque feature à moyenne 0 et écart-type 1, ce qui est crucial\n",
    "# pour les modèles sensibles à l'échelle (SVM, MLP, k-NN, etc.).\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit_transform sur X_train : apprend les moyennes/écarts-types puis transforme\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# transform sur X_test : applique EXACTEMENT la même transformation (pas de fuite d'info)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nStandardization applied: mean = 0, std = 1\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) Rééquilibrage des classes avec SMOTE sur l'entraînement\n",
    "# ---------------------------------------------------------------------\n",
    "# SMOTE génère de nouveaux exemples synthétiques de la classe minoritaire (ici les malins)\n",
    "# en interpolant entre voisins proches, afin d'obtenir un jeu de train équilibré.\n",
    "smote = SMOTE(random_state=42)  # random_state=42 pour rendre l'échantillonnage reproductible\n",
    "\n",
    "# On applique SMOTE UNIQUEMENT sur X_train_scaled, y_train (jamais sur le test)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nTrain class distribution (after SMOTE):\")\n",
    "print(f\"  Benign (0): {np.bincount(y_train_smote)[0]}\")\n",
    "print(f\"  Malignant (1): {np.bincount(y_train_smote)[1]}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 7) Split supplémentaire pour la recherche d'hyperparamètres\n",
    "# ---------------------------------------------------------------------\n",
    "# Pour la validation (tuning), on découpe de nouveau X_train_scaled en sous-ensemble d'entraînement\n",
    "# et de validation, afin d'éviter toute fuite d'information en utilisant le test pour le tuning.\n",
    "# test_size=0.3 : 30 % de l'ancien train devient validation.\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# On crée une deuxième instance de SMOTE pour rééquilibrer le sous-ensemble utilisé pour le tuning\n",
    "smote_tune = SMOTE(random_state=42)\n",
    "X_train_sub_smote, y_train_sub_smote = smote_tune.fit_resample(X_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAVpyyeY4y4k"
   },
   "source": [
    "# 6. Modeling\n",
    "\n",
    "We compare a set of classical and neural models under a unified experimental protocol. For each model we perform hyperparameter tuning on a validation split (`X_train_sub`, `X_val`), then retrain the best configuration on the SMOTE-balanced training data (`X_train_smote`) before evaluating on the held-out test set. This section defines the candidate models that will later be compared via metrics, confusion matrices, and learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03XKW_VN5K40"
   },
   "source": [
    "## 6.1 Linear Regression (SGDRegressor baseline)\n",
    "\n",
    "We use `SGDRegressor` with a squared-error loss as a simple linear baseline model. Its continuous outputs are thresholded at 0.5 to obtain class labels and rescaled with `MinMaxScaler` to approximate probabilities for ROC–AUC computation. Learning rate and number of iterations are selected to maximize validation AUC, after which the best model is retrained on the SMOTE-balanced training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iijQfns5L3Q"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 6.1 Régression linéaire (baseline avec SGDRegressor)\n",
    "# =====================================================================\n",
    "\n",
    "# Liste des taux d'apprentissage candidats pour la descente de gradient stochastique.\n",
    "# 1e-4, 1e-3, 1e-2 : on explore trois ordres de grandeur pour contrôler la taille des pas de mise à jour.\n",
    "learning_rates = [1e-4, 1e-3, 1e-2]\n",
    "\n",
    "# Liste des nombres maximum d'itérations (passes sur les données) testés.\n",
    "# 500, 1000, 2000 : plus le nombre est grand, plus le modèle peut converger finement, mais avec un risque de sur-apprentissage.\n",
    "iterations = [500, 1000, 2000]\n",
    "\n",
    "# Meilleure valeur d'AUC observée jusqu'à présent.\n",
    "# On l'initialise à -inf pour être sûr que la première configuration testée sera retenue.\n",
    "best_auc_lr = -np.inf\n",
    "\n",
    "# Hyperparamètres optimaux (taux d'apprentissage et nombre d'itérations) trouvés pendant la recherche.\n",
    "best_eta = None\n",
    "best_iter = None\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Boucle de recherche d'hyperparamètres sur (eta0, max_iter)\n",
    "# ---------------------------------------------------------------------\n",
    "for eta in learning_rates:           # eta : taux d'apprentissage initial (eta0) testé\n",
    "    for it in iterations:            # it : nombre maximum d'itérations testé\n",
    "        # Création d'un modèle de régression linéaire entraîné par SGD\n",
    "        linear_model = SGDRegressor(\n",
    "            loss='squared_error',     # fonction de perte : erreur quadratique moyenne (régression linéaire)\n",
    "            learning_rate='constant', # taux d'apprentissage constant (utilise eta0 à chaque itération)\n",
    "            eta0=eta,                 # taux d'apprentissage testé dans la boucle\n",
    "            max_iter=it,              # nombre maximal de passes sur les données\n",
    "            random_state=42           # graine pour rendre l'entraînement reproductible\n",
    "        )\n",
    "        # Entraînement sur le sous-ensemble de train utilisé pour le tuning (sans SMOTE global)\n",
    "        linear_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "        # Prédiction continue (valeurs réelles entre -inf et +inf) sur la validation\n",
    "        linear_y_val_continuous = linear_model.predict(X_val)\n",
    "\n",
    "        # Seuil à 0,5 pour obtenir des prédictions de classe (0 ou 1) à partir des sorties continues\n",
    "        lr_y_val_pred = (linear_y_val_continuous >= 0.5).astype(int)\n",
    "\n",
    "        # Import local de MinMaxScaler pour transformer les sorties continues en pseudo‑probabilités dans [0, 1]\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        prob_scaler = MinMaxScaler()  # normalise les valeurs continues sur l'intervalle [0, 1]\n",
    "\n",
    "        # On ajuste le scaler sur les prédictions d'entraînement pour apprendre le min/max des scores\n",
    "        linear_y_train_continuous = linear_model.predict(X_train_sub)\n",
    "        prob_scaler.fit(linear_y_train_continuous.reshape(-1, 1))\n",
    "\n",
    "        # On transforme ensuite les scores de validation en pseudo‑probabilités entre 0 et 1\n",
    "        lr_y_val_proba = prob_scaler.transform(\n",
    "            linear_y_val_continuous.reshape(-1, 1)\n",
    "        ).flatten()\n",
    "\n",
    "        # Calcul de l'AUC ROC sur le jeu de validation pour cette configuration (eta, it)\n",
    "        auc = roc_auc_score(y_val, lr_y_val_proba)\n",
    "\n",
    "        # Si l'AUC est meilleure que la meilleure actuelle, on met à jour les hyperparamètres optimaux\n",
    "        if auc > best_auc_lr:\n",
    "            best_auc_lr = auc   # nouvelle meilleure AUC\n",
    "            best_eta = eta      # meilleur taux d'apprentissage trouvé\n",
    "            best_iter = it      # meilleur nombre d'itérations trouvé\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Ré‑entraînement du meilleur modèle sur l'ensemble d'entraînement SMOTE\n",
    "# ---------------------------------------------------------------------\n",
    "linear_model = SGDRegressor(\n",
    "    loss='squared_error',        # même type de perte que pendant le tuning\n",
    "    learning_rate='constant',    # même stratégie de taux d'apprentissage\n",
    "    eta0=best_eta,               # taux d'apprentissage optimal trouvé\n",
    "    max_iter=best_iter,          # nombre d'itérations optimal trouvé\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement final sur les données d'entraînement rééquilibrées (X_train_smote, y_train_smote)\n",
    "linear_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prédictions continues sur le jeu de test (valeurs réelles)\n",
    "linear_y_test_continuous = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Conversion en prédictions de classe binaires par seuillage à 0,5\n",
    "lr_y_test_pred = (linear_y_test_continuous >= 0.5).astype(int)\n",
    "\n",
    "# Re‑ajustement d'un MinMaxScaler sur les scores continus d'entraînement SMOTE\n",
    "prob_scaler = MinMaxScaler()\n",
    "linear_y_train_continuous = linear_model.predict(X_train_smote)\n",
    "prob_scaler.fit(linear_y_train_continuous.reshape(-1, 1))\n",
    "\n",
    "# Transformation des scores de test en pseudo‑probabilités dans [0, 1]\n",
    "lr_y_test_proba = prob_scaler.transform(\n",
    "    linear_y_test_continuous.reshape(-1, 1)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RF3g_8Xa5Nfh"
   },
   "source": [
    "## 6.2 Logistic Regression (Softmax classifier)\n",
    "\n",
    "Logistic regression serves as a strong linear probabilistic classifier and is a key reference model in the paper. We tune the regularization strength `C`, solver, and maximum iterations on the validation set using ROC–AUC, then retrain the best configuration on `X_train_smote`. The resulting model provides well-calibrated probabilities and a clear decision boundary, against which more complex models are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdVh1O-v5Oms"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 6.2 Régression logistique (classifieur Softmax)\n",
    "# =====================================================================\n",
    "\n",
    "# Liste de valeurs candidates pour le paramètre de régularisation C.\n",
    "# C contrôle la pénalisation des poids : petites valeurs = forte régularisation, grandes valeurs = modèle plus flexible.\n",
    "C_values = [0.1, 1, 10]\n",
    "\n",
    "# Liste des solveurs pris en charge par scikit-learn pour la régression logistique binaire.\n",
    "# - 'lbfgs' : quasi-Newton, efficace pour des jeux de données de taille moyenne\n",
    "# - 'liblinear' : utilise la bibliothèque LIBLINEAR, stable pour des jeux de données petits/moyens\n",
    "# - 'newton-cg' : variante de Newton conjugué, adaptée au softmax\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg']\n",
    "\n",
    "# Nombres maximum d'itérations testés pour s'assurer de la convergence.\n",
    "# Plus max_iter est grand, plus l'optimisation peut converger, au prix d'un temps d'entraînement plus long.\n",
    "iterations = [1000, 3000, 5000]\n",
    "\n",
    "# Meilleure AUC observée jusqu'à présent pour la régression logistique.\n",
    "best_auc_softmax = -np.inf\n",
    "\n",
    "# Hyperparamètres optimaux retenus : C, solveur et max_iter.\n",
    "best_softmax_C = None\n",
    "best_softmax_solver = None\n",
    "best_softmax_max_iter = None\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Boucle de recherche d'hyperparamètres (C, solver, max_iter)\n",
    "# ---------------------------------------------------------------------\n",
    "for C_val in C_values:            # C_val : valeur candidate de C\n",
    "    for solver in solvers:        # solver : type d'algorithme d'optimisation utilisé\n",
    "        for it in iterations:     # it : nombre maximal d'itérations\n",
    "            # Instanciation d'un modèle de régression logistique\n",
    "            softmax_model = LogisticRegression(\n",
    "                C=C_val,             # intensité de la régularisation (inverse de lambda)\n",
    "                solver=solver,       # solveur utilisé pour optimiser la log‑vraisemblance\n",
    "                max_iter=it,         # borne supérieure sur le nombre d'itérations d'optimisation\n",
    "                random_state=42      # graine pour la reproductibilité\n",
    "            )\n",
    "            # Entraînement sur le sous-ensemble de train pour le tuning\n",
    "            softmax_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "            # Probabilités prédites pour la classe positive (maligne = 1) sur la validation\n",
    "            softmax_y_val_proba = softmax_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            # Calcul de l'AUC ROC sur le jeu de validation pour évaluer cette configuration\n",
    "            auc = roc_auc_score(y_val, softmax_y_val_proba)\n",
    "\n",
    "            # Mise à jour des meilleurs hyperparamètres si l'AUC est améliorée\n",
    "            if auc > best_auc_softmax:\n",
    "                best_auc_softmax = auc       # nouvelle meilleure AUC\n",
    "                best_softmax_C = C_val       # meilleure valeur de C trouvée\n",
    "                best_softmax_solver = solver # meilleur solveur trouvé\n",
    "                best_softmax_max_iter = it   # meilleur nombre d'itérations trouvé\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Ré‑entraînement du meilleur modèle de régression logistique sur SMOTE\n",
    "# ---------------------------------------------------------------------\n",
    "softmax_model = LogisticRegression(\n",
    "    C=best_softmax_C,                # C optimal\n",
    "    solver=best_softmax_solver,      # solveur optimal\n",
    "    max_iter=best_softmax_max_iter,  # nombre d'itérations optimal\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement final sur les données d'entraînement rééquilibrées\n",
    "softmax_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Probabilités prévues pour la classe positive sur le jeu de test\n",
    "softmax_y_test_proba = softmax_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Prédictions de classe (0/1) sur le test en utilisant le seuil par défaut de scikit-learn (0,5)\n",
    "softmax_y_test_pred = softmax_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khszrDLM5RGw"
   },
   "source": [
    "## 6.3 MLP (feedforward neural network)\n",
    "\n",
    "This model is a fully connected neural network that can capture non-linear relationships between features and malignancy. We perform a grid search over the number and size of hidden layers, weight decay (`alpha`), learning rate, and maximum epochs, selecting the configuration that maximizes validation ROC–AUC. The chosen MLP is then retrained on the balanced training set and evaluated on the test set alongside the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ck_HScn5Sn5"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 6.3 MLP (réseau de neurones fully-connected)\n",
    "# =====================================================================\n",
    "\n",
    "# Taux d'apprentissage initiaux candidats pour l'optimiseur interne du MLP.\n",
    "learning_rates = [1e-4, 1e-3]\n",
    "\n",
    "# Nombres d'itérations maximales (époques) à tester pour l'entraînement du MLP.\n",
    "iterations = [1000, 3000, 5000]\n",
    "\n",
    "# Architectures candidates pour les couches cachées :\n",
    "# - (200, 200) : 2 couches de 200 neurones\n",
    "# - (500, 500, 500) : 3 couches plus larges de 500 neurones\n",
    "# - (300, 300, 300) : 3 couches intermédiaires de 300 neurones\n",
    "hidden_layers = [(200, 200), (500, 500, 500), (300, 300, 300)]\n",
    "\n",
    "# Valeurs candidates de la régularisation L2 (weight decay) via le paramètre alpha.\n",
    "# Plus alpha est grand, plus les poids sont pénalisés (modèle plus simple, moins de sur-apprentissage).\n",
    "alphas = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "# Suivi de la meilleure AUC obtenue pendant la recherche d'hyperparamètres.\n",
    "best_auc_mlp = -np.inf\n",
    "\n",
    "# Hyperparamètres optimaux retenus pour le MLP.\n",
    "best_mlp_hidden = None\n",
    "best_mlp_alpha = None\n",
    "best_mlp_lr = None\n",
    "best_mlp_it = None\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Boucle de recherche en grille sur (architecture, alpha, lr, max_iter)\n",
    "# ---------------------------------------------------------------------\n",
    "for hls in hidden_layers:          # hls : tuple décrivant la taille de chaque couche cachée\n",
    "    for alpha in alphas:           # alpha : coefficient de régularisation L2\n",
    "        for lr in learning_rates:  # lr : learning_rate_init\n",
    "            for it in iterations:  # it : nombre maximal d'itérations\n",
    "                # Instanciation du MLP avec un ensemble donné d'hyperparamètres\n",
    "                mlp_model = MLPClassifier(\n",
    "                    hidden_layer_sizes=hls,        # architecture des couches cachées testée\n",
    "                    learning_rate_init=lr,         # taux d'apprentissage initial\n",
    "                    learning_rate='adaptive',      # le taux s'adapte en fonction de la progression de l'erreur\n",
    "                    alpha=alpha,                   # pénalisation L2 des poids\n",
    "                    max_iter=it,                   # nombre maximal d'itérations\n",
    "                    batch_size=128,                # taille du mini-batch (stabilise les mises à jour)\n",
    "                    n_iter_no_change=20,           # nombre d'itérations sans amélioration avant arrêt anticipé\n",
    "                    early_stopping=True,           # active l'arrêt anticipé basé sur la validation interne\n",
    "                    random_state=42,               # graine pour reproductibilité\n",
    "                    validation_fraction=0.1        # part de l'entraînement utilisée comme validation interne\n",
    "                )\n",
    "\n",
    "                # Entraînement du MLP sur le sous-ensemble de train pour le tuning\n",
    "                mlp_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "                # Probabilités pour la classe positive sur le jeu de validation externe X_val\n",
    "                mlp_y_val_proba = mlp_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "                # Calcul de l'AUC ROC pour cette configuration d'hyperparamètres\n",
    "                auc = roc_auc_score(y_val, mlp_y_val_proba)\n",
    "\n",
    "                # Mise à jour des meilleurs hyperparamètres si l'AUC est améliorée\n",
    "                if auc > best_auc_mlp:\n",
    "                    best_auc_mlp = auc\n",
    "                    best_mlp_hidden = hls\n",
    "                    best_mlp_alpha = alpha\n",
    "                    best_mlp_lr = lr\n",
    "                    best_mlp_it = it\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Ré‑entraînement du MLP avec les meilleurs hyperparamètres sur SMOTE\n",
    "# ---------------------------------------------------------------------\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=best_mlp_hidden,  # architecture optimale\n",
    "    learning_rate_init=best_mlp_lr,      # taux d'apprentissage optimal\n",
    "    alpha=best_mlp_alpha,                # régularisation L2 optimale\n",
    "    max_iter=best_mlp_it,                # nombre d'itérations optimal\n",
    "    early_stopping=True,                 # arrêt anticipé basé sur validation interne\n",
    "    random_state=42,\n",
    "    verbose=0,                           # verbose=0 : ne pas afficher les logs d'entraînement\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "# Entraînement final sur les données d'entraînement rééquilibrées\n",
    "mlp_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Probabilités pour la classe positive sur le jeu de test\n",
    "mlp_y_test_proba = mlp_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Prédictions de classe (0/1) sur le jeu de test\n",
    "mlp_y_test_pred = mlp_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogpYfDhG5UE4"
   },
   "source": [
    "## 6.4 L2-SVM (linear support vector machine)\n",
    "\n",
    "We train a linear SVM with probabilistic outputs to obtain a maximum-margin classifier in the original feature space. The regularization parameter `C` is tuned on the validation set using ROC–AUC, and the best model is refit on `X_train_smote`. This provides a strong linear margin-based baseline that is often competitive with neural approaches on tabular biomedical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mcrh7yRu5U_x"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 6.4 L2-SVM (machine à vecteurs de support linéaire)\n",
    "# =====================================================================\n",
    "\n",
    "# Valeurs candidates pour le paramètre de régularisation C de la SVM linéaire.\n",
    "# C élevé -> marge plus petite mais moins d'erreurs d'entraînement ; C faible -> marge plus large mais plus d'erreurs permises.\n",
    "C_values = [0.1, 1, 10]\n",
    "\n",
    "# Meilleure AUC obtenue pour la SVM sur la validation.\n",
    "best_auc_svm = -np.inf\n",
    "\n",
    "# Meilleure valeur de C retenue.\n",
    "best_svm_C = None\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Boucle de recherche sur C pour la SVM linéaire\n",
    "# ---------------------------------------------------------------------\n",
    "for C in C_values:  # C : intensité de la pénalisation des erreurs\n",
    "    svm_model = SVC(\n",
    "        C=C,                  # valeur de C testée\n",
    "        kernel='linear',      # noyau linéaire : frontière de décision planaire\n",
    "        probability=True,     # active la calibration des probabilités via Platt scaling\n",
    "        random_state=42       # graine pour reproductibilité (utile surtout pour le calibrage)\n",
    "    )\n",
    "    # Entraînement de la SVM sur le sous-ensemble d'entraînement pour le tuning\n",
    "    svm_model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Probabilités prévues pour la classe positive sur la validation\n",
    "    svm_y_val_proba = svm_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Calcul de l'AUC ROC pour évaluer la qualité de la séparation des classes\n",
    "    auc = roc_auc_score(y_val, svm_y_val_proba)\n",
    "\n",
    "    # Mise à jour de la meilleure valeur de C si l'AUC est améliorée\n",
    "    if auc > best_auc_svm:\n",
    "        best_auc_svm = auc\n",
    "        best_svm_C = C\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Ré‑entraînement de la SVM linéaire avec le meilleur C sur SMOTE\n",
    "# ---------------------------------------------------------------------\n",
    "svm_model = SVC(\n",
    "    C=best_svm_C,          # meilleur paramètre C trouvé\n",
    "    kernel='linear',       # noyau linéaire\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement final sur les données d'entraînement rééquilibrées\n",
    "svm_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prédictions de classe sur le jeu de test\n",
    "svm_y_test_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Probabilités prévues pour la classe positive sur le jeu de test\n",
    "svm_y_test_proba = svm_model.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkFwtqVj5Wdu"
   },
   "source": [
    "## 6.5 k-Nearest Neighbours (L1 and L2)\n",
    "\n",
    "We evaluate instance-based learners using k-nearest neighbours with both Manhattan (L1) and Euclidean (L2) distances. For each metric we select the optimal number of neighbours `k` by maximizing validation ROC–AUC, then retrain the best L1-NN and L2-NN on the balanced training set. These models provide a non-parametric baseline that can adapt to local structure in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcRTsfaG5XjH"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 6.5 k plus proches voisins (L1 et L2)\n",
    "# =====================================================================\n",
    "\n",
    "# Ensemble de valeurs k candidates (nombre de voisins) pour les modèles k-NN.\n",
    "# De petits k (1,3) capturent des structures très locales mais sont plus sensibles au bruit.\n",
    "# Des k plus grands (7,9) lissent davantage la décision.\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Meilleure AUC pour le modèle k-NN avec distance L1 (Manhattan).\n",
    "best_auc_knn_l1 = -np.inf\n",
    "best_knn_l1_k = None  # valeur optimale de k pour L1\n",
    "\n",
    "# Meilleure AUC pour le modèle k-NN avec distance L2 (euclidienne).\n",
    "best_auc_knn_l2 = -np.inf\n",
    "best_knn_l2_k = None  # valeur optimale de k pour L2\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Boucle sur les différentes valeurs de k pour L1 et L2\n",
    "# ---------------------------------------------------------------------\n",
    "for k in k_values:\n",
    "    # ------- k-NN avec distance de Manhattan (L1) -------\n",
    "    knn_l1 = KNeighborsClassifier(\n",
    "        n_neighbors=k,        # nombre de voisins pris en compte\n",
    "        metric='minkowski',   # métrique Minkowski générale\n",
    "        p=1                   # p=1 => distance de Manhattan (L1)\n",
    "    )\n",
    "    knn_l1.fit(X_train_sub, y_train_sub)  # entraînement sur le sous-ensemble d'entraînement\n",
    "\n",
    "    # Probabilités pour la classe positive sur la validation\n",
    "    knn_l1_y_val_proba = knn_l1.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # AUC ROC pour ce k avec distance L1\n",
    "    auc = roc_auc_score(y_val, knn_l1_y_val_proba)\n",
    "    if auc > best_auc_knn_l1:\n",
    "        best_auc_knn_l1 = auc\n",
    "        best_knn_l1_k = k\n",
    "\n",
    "    # ------- k-NN avec distance euclidienne (L2) -------\n",
    "    knn_l2 = KNeighborsClassifier(\n",
    "        n_neighbors=k,        # même k testé\n",
    "        metric='minkowski',   # métrique Minkowski\n",
    "        p=2                   # p=2 => distance euclidienne (L2)\n",
    "    )\n",
    "    knn_l2.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    # Probabilités pour la classe positive sur la validation\n",
    "    knn_l2_y_val_proba = knn_l2.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # AUC ROC pour ce k avec distance L2\n",
    "    auc = roc_auc_score(y_val, knn_l2_y_val_proba)\n",
    "    if auc > best_auc_knn_l2:\n",
    "        best_auc_knn_l2 = auc\n",
    "        best_knn_l2_k = k\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Ré‑entraînement des meilleurs modèles k-NN (L1 et L2) sur SMOTE\n",
    "# ---------------------------------------------------------------------\n",
    "# Modèle k-NN L1 avec le meilleur k trouvé.\n",
    "knn_l1 = KNeighborsClassifier(\n",
    "    n_neighbors=best_knn_l1_k,\n",
    "    metric='minkowski',\n",
    "    p=1\n",
    ")\n",
    "knn_l1.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prédictions de classe et probabilités sur le jeu de test\n",
    "knn_l1_y_test_pred = knn_l1.predict(X_test_scaled)\n",
    "knn_l1_y_test_proba = knn_l1.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Modèle k-NN L2 avec le meilleur k trouvé.\n",
    "knn_l2 = KNeighborsClassifier(\n",
    "    n_neighbors=best_knn_l2_k,\n",
    "    metric='minkowski',\n",
    "    p=2\n",
    ")\n",
    "knn_l2.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prédictions de classe et probabilités sur le jeu de test\n",
    "knn_l2_y_test_pred = knn_l2.predict(X_test_scaled)\n",
    "knn_l2_y_test_proba = knn_l2.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ_oFQCa5ZzS"
   },
   "source": [
    "## 6.6 GRU–SVM hybrid\n",
    "\n",
    "Finally, we build a hybrid model that learns a non-linear representation with a GRU network and then applies an RBF-kernel SVM on the extracted features. The GRU is trained with early stopping on a reshaped version of the tabular data, and its penultimate layer is used as a compact feature embedding. We then tune the SVM regularization parameter `C` on these embeddings and evaluate the resulting GRU–SVM on the test set, providing a deep learning–based point of comparison with the classical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzoCMXS95a8h",
    "outputId": "237a79ff-714b-4dc0-eb21-f9158ef501ac"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 6.6 Hybride GRU–SVM\n",
    "# =====================================================================\n",
    "\n",
    "# Valeurs candidates de C pour la SVM à noyau RBF appliquée sur les features extraites par le GRU.\n",
    "C_values = [0.1, 1, 5]\n",
    "\n",
    "# Meilleure AUC obtenue pour la combinaison GRU + SVM.\n",
    "best_auc_gru = -np.inf\n",
    "\n",
    "# Hyperparamètres/infos retenus pour le meilleur modèle GRU–SVM.\n",
    "best_gru_units = None   # nombre de neurones GRU (fixé à 64 ici, mais conservé pour la cohérence)\n",
    "best_gru_svm_C = None   # meilleure valeur de C pour la SVM\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Préparation des entrées pour le GRU\n",
    "# ---------------------------------------------------------------------\n",
    "# Nombre de caractéristiques d'entrée (dimensions des vecteurs de features tabulaires).\n",
    "n_features = X_train_sub_smote.shape[1]\n",
    "\n",
    "# Reshape des données tabulaires en séquences de longueur n_features avec 1 feature par \"time-step\".\n",
    "# Forme attendue par le GRU : (n_samples, timesteps, features_par_timestep)\n",
    "X_train_gru = X_train_sub_smote.reshape(X_train_sub_smote.shape[0], n_features, 1)\n",
    "X_val_gru = X_val.reshape(X_val.shape[0], n_features, 1)\n",
    "X_test_gru = X_test_scaled.reshape(X_test_scaled.shape[0], n_features, 1)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Définition de l'architecture GRU\n",
    "# ---------------------------------------------------------------------\n",
    "gru_model = Sequential([\n",
    "    # Couche d'entrée explicitant la forme des séquences d'entrée\n",
    "    Input(shape=(n_features, 1)),\n",
    "\n",
    "    # Couche GRU avec 64 unités : résume la séquence en un vecteur de taille 64\n",
    "    GRU(64, return_sequences=False),\n",
    "\n",
    "    # Dropout 0.3 : éteint aléatoirement 30 % des unités pour limiter le sur-apprentissage\n",
    "    Dropout(0.3),  # réduit par rapport à 0.6 pour garder plus de capacité\n",
    "\n",
    "    # Couche dense intermédiaire de 32 neurones avec activation ReLU pour plus de non‑linéarité\n",
    "    Dense(32, activation='relu'),\n",
    "\n",
    "    # BatchNormalization : normalise les activations pour stabiliser et accélérer l'entraînement\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # Couche de sortie de taille 1 avec sigmoïde : renvoie une probabilité de malignité entre 0 et 1\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilation du modèle GRU\n",
    "# - Adam : optimiseur adaptatif bien adapté aux réseaux profonds\n",
    "# - binary_crossentropy : perte standard pour la classification binaire\n",
    "# - metrics=['accuracy'] : suivre l'accuracy pendant l'entraînement\n",
    "gru_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),  # taux d'apprentissage 1e-3, valeur classique stable\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# EarlyStopping : arrête l'entraînement si la perte de validation ne s'améliore plus.\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # on surveille la perte de validation\n",
    "    patience=30,              # on attend 30 époques sans amélioration avant d'arrêter\n",
    "    restore_best_weights=True,# on restaure les poids correspondant à la meilleure val_loss\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Entraînement du GRU sur les données séquentielles dérivées de X_train_sub_smote\n",
    "# - epochs=500 : nombre maximal d'époques (l'early stopping arrêtera plus tôt si nécessaire)\n",
    "# - batch_size=128 : taille du mini-batch\n",
    "# - validation_split=0.2 : 20 % des données d'entraînement utilisés comme validation interne\n",
    "# - callbacks=[early_stopping] : applique l'arrêt anticipé décrit ci‑dessus\n",
    "gru_model.fit(\n",
    "    X_train_gru, y_train_sub_smote,\n",
    "    epochs=500,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Extraction des caractéristiques apprises par le GRU\n",
    "# ---------------------------------------------------------------------\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# On définit un modèle intermédiaire qui prend la même entrée que le GRU\n",
    "# mais dont la sortie est la couche dense de 32 neurones (avant la normalisation batch et la sortie sigmoïde).\n",
    "model_input = gru_model.layers[0].input\n",
    "feature_extractor = Model(\n",
    "    inputs=model_input,\n",
    "    outputs=gru_model.layers[-3].output  # couche Dense(32, activation='relu')\n",
    ")\n",
    "\n",
    "# Extraction des features pour train / val / test (sorties 32D)\n",
    "gru_train_features = feature_extractor.predict(X_train_gru, verbose=0)\n",
    "gru_val_features = feature_extractor.predict(X_val_gru, verbose=0)\n",
    "gru_test_features = feature_extractor.predict(X_test_gru, verbose=0)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Recherche du meilleur C pour la SVM RBF sur les features extraites\n",
    "# ---------------------------------------------------------------------\n",
    "for C_val in C_values:\n",
    "    gru_svm_model = SVC(\n",
    "        kernel='rbf',      # noyau RBF pour capturer des frontières non linéaires dans l'espace des embeddings\n",
    "        C=C_val,           # valeur de C testée\n",
    "        probability=True   # permet d'obtenir des probabilités calibrées\n",
    "    )\n",
    "    gru_svm_model.fit(gru_train_features, y_train_sub_smote)\n",
    "\n",
    "    # Probabilités pour la classe positive sur les embeddings de validation\n",
    "    gru_svm_y_val_proba = gru_svm_model.predict_proba(gru_val_features)[:, 1]\n",
    "\n",
    "    # AUC ROC pour cette valeur de C\n",
    "    auc = roc_auc_score(y_val, gru_svm_y_val_proba)\n",
    "    if auc > best_auc_gru:\n",
    "        best_auc_gru = auc\n",
    "        best_gru_units = 64      # taille de la couche GRU (fixe dans ce notebook)\n",
    "        best_gru_svm_C = C_val   # meilleure valeur de C pour la SVM\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Entraînement final de la SVM RBF GRU–SVM sur l'ensemble train complet\n",
    "# ---------------------------------------------------------------------\n",
    "gru_svm_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=best_gru_svm_C,      # meilleur C trouvé\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement de la SVM sur les features GRU extraites du train complet\n",
    "gru_svm_model.fit(gru_train_features, y_train_sub_smote)\n",
    "\n",
    "# Prédictions de classe et probabilités sur le jeu de test (dans l'espace des embeddings GRU)\n",
    "gru_svm_y_test_pred = gru_svm_model.predict(gru_test_features)\n",
    "gru_svm_y_test_proba = gru_svm_model.predict_proba(gru_test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zN0WBt25cTg"
   },
   "source": [
    "# 7. Evaluation\n",
    "\n",
    "We now evaluate all tuned models on the held-out test set using a comprehensive set of metrics (accuracy, ROC–AUC, precision, recall, F1-score, specificity, FPR/FNR, TPR). The resulting table (`results_df`) summarizes global performance and supports the ranking of models reported in the conclusion, while the printed hyperparameters document the exact configurations used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gsPgq4m5dQM",
    "outputId": "4795e055-d2e1-49a9-dc39-18c89778ed14"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 7. Évaluation : calcul des métriques sur le jeu de test\n",
    "# =====================================================================\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, roc_auc_score,\n",
    "    recall_score, precision_score, f1_score\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Fonction utilitaire pour calculer un ensemble complet de métriques\n",
    "# ---------------------------------------------------------------------\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    \"\"\"Calcule plusieurs métriques de classification binaire à partir\n",
    "    des prédictions discrètes (y_pred) et probabilistes (y_proba).\"\"\"\n",
    "\n",
    "    # Matrice de confusion 2x2 :\n",
    "    # [[TN, FP],\n",
    "    #  [FN, TP]]\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    return {\n",
    "        # Accuracy : proportion globale de prédictions correctes\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "\n",
    "        # ROC-AUC : aire sous la courbe ROC (sensibilité vs 1-spécificité)\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba),\n",
    "\n",
    "        # Recall (sensibilité) : TP / (TP + FN), proportion de malins correctement détectés\n",
    "        'recall': recall_score(y_true, y_pred, pos_label=1),\n",
    "\n",
    "        # Précision : TP / (TP + FP), proportion de prédictions \"malin\" correctes\n",
    "        'precision': precision_score(y_true, y_pred, pos_label=1),\n",
    "\n",
    "        # F1-score : moyenne harmonique précision / rappel\n",
    "        'f1_score': f1_score(y_true, y_pred, pos_label=1),\n",
    "\n",
    "        # Spécificité : TN / (TN + FP), capacité à reconnaître les cas bénins\n",
    "        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0.0,\n",
    "\n",
    "        # FPR (False Positive Rate) : FP / (FP + TN)\n",
    "        'FPR': fp / (fp + tn) if (fp + tn) > 0 else 0.0,\n",
    "\n",
    "        # FNR (False Negative Rate) : FN / (FN + TP)\n",
    "        'FNR': fn / (fn + tp) if (fn + tp) > 0 else 0.0,\n",
    "\n",
    "        # TPR (True Positive Rate) : identique au recall ici\n",
    "        'TPR': tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Calcul des métriques pour chaque modèle sur le jeu de test\n",
    "# ---------------------------------------------------------------------\n",
    "test_results = {\n",
    "    'Linear Regression': calculate_metrics(y_test, lr_y_test_pred, lr_y_test_proba),\n",
    "    'Softmax Regression': calculate_metrics(y_test, softmax_y_test_pred, softmax_y_test_proba),\n",
    "    'MLP': calculate_metrics(y_test, mlp_y_test_pred, mlp_y_test_proba),\n",
    "    'L2-SVM': calculate_metrics(y_test, svm_y_test_pred, svm_y_test_proba),\n",
    "    'L1-NN': calculate_metrics(y_test, knn_l1_y_test_pred, knn_l1_y_test_proba),\n",
    "    'L2-NN': calculate_metrics(y_test, knn_l2_y_test_pred, knn_l2_y_test_proba),\n",
    "    'GRU-SVM': calculate_metrics(y_test, gru_svm_y_test_pred, gru_svm_y_test_proba)\n",
    "}\n",
    "\n",
    "# Conversion du dictionnaire de résultats en DataFrame pour un affichage tabulaire\n",
    "results_df = pd.DataFrame(test_results).T  # .T : transpose pour avoir un modèle par ligne\n",
    "print(results_df)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Récapitulatif des meilleurs hyperparamètres utilisés pour chaque modèle\n",
    "# ---------------------------------------------------------------------\n",
    "# Ce dictionnaire permet de documenter précisément les configurations\n",
    "# des modèles qui ont conduit aux résultats reportés.\n",
    "best_hyperparameters = {\n",
    "    \"Linear Regression\": {\n",
    "        \"eta0\": best_eta,              # meilleur taux d'apprentissage pour SGDRegressor\n",
    "        \"max_iter\": best_iter          # meilleur nombre d'itérations pour SGDRegressor\n",
    "    },\n",
    "    \"Softmax Regression\": {\n",
    "        \"C\": best_softmax_C,           # meilleur C pour la régression logistique\n",
    "        \"solver\": best_softmax_solver  # meilleur solveur pour la régression logistique\n",
    "    },\n",
    "    \"MLP\": {\n",
    "        \"hidden_layer_sizes\": best_mlp_hidden,  # meilleure architecture cachée\n",
    "        \"alpha\": best_mlp_alpha                 # meilleur poids de régularisation L2\n",
    "    },\n",
    "    \"L2-SVM\": {\n",
    "        \"C\": best_svm_C,               # meilleur C pour la SVM linéaire\n",
    "        \"kernel\": \"linear\"            # noyau utilisé\n",
    "    },\n",
    "    \"L1-NN\": {\n",
    "        \"k\": best_knn_l1_k,           # meilleur nombre de voisins pour k-NN L1\n",
    "        \"metric\": \"manhattan\"        # distance de Manhattan (L1)\n",
    "    },\n",
    "    \"L2-NN\": {\n",
    "        \"k\": best_knn_l2_k,           # meilleur nombre de voisins pour k-NN L2\n",
    "        \"metric\": \"euclidean\"        # distance euclidienne (L2)\n",
    "    },\n",
    "    \"GRU-SVM\": {\n",
    "        \"GRU_units\": best_gru_units,  # taille de la couche GRU\n",
    "        \"SVM_C\": best_gru_svm_C       # meilleur C pour la SVM RBF\n",
    "    }\n",
    "}\n",
    "\n",
    "# Affichage lisible des hyperparamètres retenus pour chaque modèle\n",
    "for model, params in best_hyperparameters.items():\n",
    "    print(f\"{model}:\")\n",
    "    for p, v in params.items():\n",
    "        print(f\"  - {p}: {v}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkstGBSs5e1U"
   },
   "source": [
    "# 8. Confusion Matrices\n",
    "\n",
    "To complement the aggregate metrics, we plot the confusion matrix of each model on the test set. These heatmaps reveal the balance between true positives, true negatives, false positives and especially false negatives, which are critical in cancer detection. Together with the metric table, they help assess which models best limit missed malignant cases while keeping the false-alarm rate acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_yeFydus5f1I",
    "outputId": "f723e104-4668-40d7-b8ce-ad44a35eb19e"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 8. Matrices de confusion : visualisation détaillée des erreurs\n",
    "# =====================================================================\n",
    "\n",
    "# Liste des modèles et de leurs prédictions de classe sur le jeu de test.\n",
    "# Chaque tuple contient : (nom lisible, vecteur y_pred correspondant).\n",
    "models_data = [\n",
    "    ('Linear Regression', lr_y_test_pred),\n",
    "    ('Softmax Regression', softmax_y_test_pred),\n",
    "    ('MLP', mlp_y_test_pred),\n",
    "    ('L2-SVM', svm_y_test_pred),\n",
    "    ('L1-NN', knn_l1_y_test_pred),\n",
    "    ('L2-NN', knn_l2_y_test_pred),\n",
    "    ('GRU-SVM', gru_svm_y_test_pred)\n",
    "]\n",
    "\n",
    "# Nombre total de modèles à afficher.\n",
    "n_models = len(models_data)\n",
    "\n",
    "# Disposition de la grille de sous-graphiques : 3 colonnes, n_rows lignes.\n",
    "n_cols = 3\n",
    "n_rows = (n_models + n_cols - 1) // n_cols  # division plafond pour couvrir tous les modèles\n",
    "\n",
    "# Création de la figure et des axes pour les heatmaps de matrices de confusion.\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4*n_rows))\n",
    "\n",
    "# Gestion du cas où il n'y a qu'une seule ligne : axes peut être un seul axe ou un tableau.\n",
    "if n_rows == 1:\n",
    "    axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
    "else:\n",
    "    axes = axes.flatten()  # mise à plat pour indexer simplement avec idx\n",
    "\n",
    "# Boucle sur chaque modèle pour tracer sa matrice de confusion.\n",
    "for idx, (name, y_pred) in enumerate(models_data):\n",
    "    ax = axes[idx]  # axe courant\n",
    "\n",
    "    # Matrice de confusion entre les vraies étiquettes y_test et les prédictions y_pred\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Heatmap Seaborn de la matrice de confusion\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,                    # affiche les nombres dans les cases\n",
    "        fmt='d',                       # format entier\n",
    "        cmap='Blues',                  # colormap bleue\n",
    "        ax=ax,\n",
    "        xticklabels=['Benign', 'Malignant'],  # labels de l'axe x\n",
    "        yticklabels=['Benign', 'Malignant']   # labels de l'axe y\n",
    "    )\n",
    "    ax.set_title(name, fontsize=10)\n",
    "\n",
    "# Si la grille contient plus d'axes que de modèles (cases vides), on les désactive.\n",
    "for idx in range(n_models, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# Ajuste automatiquement les espacements pour éviter le chevauchement des titres/étiquettes.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6qFLgQ35hcb"
   },
   "source": [
    "# 9. Learning Curves\n",
    "\n",
    "In this section we analyse how model performance evolves with training data and training epochs. Cell **9\\*** uses `learning_curve` to show training and validation accuracy as a function of the number of training examples for the tuned models from Section 6, providing evidence about bias/variance and data efficiency. Cell **9.2** studies optimization dynamics for proxy SGD-based models, helping to diagnose overfitting and the stability of the training procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CAR3l2M35i0f",
    "outputId": "0a14ee1f-edd0-4548-90a1-98a53a77cb36"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 9*. Courbes d'apprentissage pour les modèles optimisés (Section 6)\n",
    "# =====================================================================\n",
    "\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Score personnalisé pour traiter la régression linéaire comme un classifieur\n",
    "# ---------------------------------------------------------------------\n",
    "# SGDRegressor renvoie des valeurs continues ; pour tracer une courbe\n",
    "# d'apprentissage en \"accuracy\", on applique un seuil à 0,5 pour obtenir\n",
    "# des prédictions binaires, puis on calcule l'accuracy classique.\n",
    "def linear_reg_classifier_accuracy(y_true, y_pred_continuous):\n",
    "    y_pred = (y_pred_continuous >= 0.5).astype(int)\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# make_scorer permet d'utiliser cette fonction comme scoring dans learning_curve\n",
    "linear_acc_scorer = make_scorer(linear_reg_classifier_accuracy)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Fonction générique pour tracer une courbe d'apprentissage (train / validation)\n",
    "# ---------------------------------------------------------------------\n",
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    X,\n",
    "    y,\n",
    "    title,\n",
    "    scoring,\n",
    "    cv,\n",
    "    ax,\n",
    "    n_jobs=None,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "):\n",
    "    # learning_curve entraîne le modèle sur des sous‑ensembles de plus en plus grands\n",
    "    # de l'ensemble d'entraînement et renvoie les scores moyens en cross‑validation.\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        train_sizes=train_sizes,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    # Moyenne et écart-type des scores (sur les folds de validation croisée)\n",
    "    train_mean = train_scores.mean(axis=1)\n",
    "    train_std = train_scores.std(axis=1)\n",
    "    val_mean = val_scores.mean(axis=1)\n",
    "    val_std = val_scores.std(axis=1)\n",
    "\n",
    "    # Courbe de score d'entraînement\n",
    "    ax.plot(train_sizes, train_mean, 'o-', label='Training', linewidth=2)\n",
    "    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15)\n",
    "\n",
    "    # Courbe de score de validation\n",
    "    ax.plot(train_sizes, val_mean, 'o-', label='Validation', linewidth=2)\n",
    "    ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.15)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Nombre d\\'exemples d\\'entraînement')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Recréation des modèles avec leurs hyperparamètres optimaux (Section 6)\n",
    "# ---------------------------------------------------------------------\n",
    "linear_est = SGDRegressor(\n",
    "    loss='squared_error',\n",
    "    learning_rate='constant',\n",
    "    eta0=best_eta,\n",
    "    max_iter=best_iter,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "softmax_est = LogisticRegression(\n",
    "    C=best_softmax_C,\n",
    "    solver=best_softmax_solver,\n",
    "    max_iter=best_softmax_max_iter,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_est = MLPClassifier(\n",
    "    hidden_layer_sizes=best_mlp_hidden,\n",
    "    learning_rate_init=best_mlp_lr,\n",
    "    learning_rate='adaptive',\n",
    "    alpha=best_mlp_alpha,\n",
    "    max_iter=best_mlp_it,\n",
    "    batch_size=128,\n",
    "    n_iter_no_change=20,\n",
    "    early_stopping=True,\n",
    "    random_state=42,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "svm_est = SVC(\n",
    "    C=best_svm_C,\n",
    "    kernel='linear',\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "knn_l1_est = KNeighborsClassifier(\n",
    "    n_neighbors=best_knn_l1_k,\n",
    "    metric='minkowski',\n",
    "    p=1\n",
    ")\n",
    "\n",
    "knn_l2_est = KNeighborsClassifier(\n",
    "    n_neighbors=best_knn_l2_k,\n",
    "    metric='minkowski',\n",
    "    p=2\n",
    ")\n",
    "\n",
    "# StratifiedKFold : cross‑validation en conservant le ratio de classes dans chaque fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste des modèles pour lesquels on trace les courbes d'apprentissage.\n",
    "# Pour la régression linéaire, on utilise le scorer personnalisé linear_acc_scorer.\n",
    "models_lc = [\n",
    "    ('Linear Regression', linear_est, linear_acc_scorer),\n",
    "    ('Softmax Regression', softmax_est, 'accuracy'),\n",
    "    ('MLP', mlp_est, 'accuracy'),\n",
    "    ('L2-SVM', svm_est, 'accuracy'),\n",
    "    ('L1-NN', knn_l1_est, 'accuracy'),\n",
    "    ('L2-NN', knn_l2_est, 'accuracy')\n",
    "]\n",
    "\n",
    "n_models = len(models_lc)\n",
    "fig, axes = plt.subplots(n_models, 1, figsize=(8, 4 * n_models))\n",
    "if n_models == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Boucle sur chaque modèle pour tracer la courbe train/validation\n",
    "for ax, (name, est, scoring) in zip(axes, models_lc):\n",
    "    plot_learning_curve(\n",
    "        est,\n",
    "        X_train_smote,\n",
    "        y_train_smote,\n",
    "        f'{name} Learning Curve (tuned model)',\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        ax=ax,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Z9snlKtZqgQ",
    "outputId": "4cf3d5f3-23d0-499f-c54e-9b05105350f6"
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 9.2 Dynamique d'optimisation pour des modèles proxy basés sur SGD\n",
    "# (et non les estimateurs finaux de la section 6)\n",
    "# =====================================================================\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Fonction utilitaire : log-loss + accuracy pour un modèle probabiliste\n",
    "# ---------------------------------------------------------------------\n",
    "def compute_loss_acc(model, X, y):\n",
    "    # Probabilités pour la classe positive\n",
    "    proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Log-loss binaire implémentée manuellement\n",
    "    loss = -np.mean(\n",
    "        y * np.log(proba + 1e-10) +            # terme pour les positifs\n",
    "        (1 - y) * np.log(1 - proba + 1e-10)    # terme pour les négatifs\n",
    "    )\n",
    "\n",
    "    # Prédictions de classe et accuracy correspondante\n",
    "    pred = model.predict(X)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    return loss, acc\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Suivi de l'évolution de la perte/accuracy pour un MLP (proxy)\n",
    "# ---------------------------------------------------------------------\n",
    "def track_mlp_history(X_train, y_train, max_iter=300):\n",
    "    # Re-split interne entraînement/validation pour le suivi des courbes\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # MLP proxy de taille (50,50,50) entraîné itérativement avec warm_start\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(50, 50, 50),\n",
    "        learning_rate_init=0.005,\n",
    "        alpha=0.05,\n",
    "        max_iter=1,          # une seule itération par appel à fit\n",
    "        random_state=42,\n",
    "        warm_start=True      # conserve les poids entre les appels successifs à fit\n",
    "    )\n",
    "\n",
    "    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
    "\n",
    "    # Boucle d'entraînement incrémental pour construire les courbes\n",
    "    for _ in range(max_iter):\n",
    "        model.fit(X_train_split, y_train_split)\n",
    "        train_loss, train_acc = compute_loss_acc(model, X_train_split, y_train_split)\n",
    "        val_loss, val_acc = compute_loss_acc(model, X_val, y_val)\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "    return history\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Suivi de l'évolution de la perte/accuracy pour d'autres modèles SGD\n",
    "# ---------------------------------------------------------------------\n",
    "def track_model_history(model_class, loss_type, X_train, y_train, max_iter=300):\n",
    "    # Re-split interne entraînement/validation\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Instanciation d'un modèle SGD (classifieur ou régression)\n",
    "    model = model_class(\n",
    "        loss=loss_type,              # type de perte : 'hinge', 'log_loss' ou 'squared_error'\n",
    "        learning_rate='constant',\n",
    "        eta0=1e-3,                   # petit taux d'apprentissage fixe\n",
    "        max_iter=1,                  # une itération par fit\n",
    "        random_state=42,\n",
    "        warm_start=True              # conserve les poids entre les fits successifs\n",
    "    )\n",
    "\n",
    "    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        model.fit(X_train_split, y_train_split)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            # Cas des modèles probabilistes : on utilise compute_loss_acc\n",
    "            train_loss, train_acc = compute_loss_acc(model, X_train_split, y_train_split)\n",
    "            val_loss, val_acc = compute_loss_acc(model, X_val, y_val)\n",
    "        else:\n",
    "            # Cas des modèles sans predict_proba (par ex. régression ou SVM hinge)\n",
    "            train_pred = model.predict(X_train_split)\n",
    "            val_pred = model.predict(X_val)\n",
    "            if loss_type == 'squared_error':\n",
    "                # Perte quadratique moyenne pour la régression\n",
    "                train_loss = np.mean((train_pred - y_train_split)**2)\n",
    "                val_loss = np.mean((val_pred - y_val)**2)\n",
    "                # Accuracy via seuillage à 0,5\n",
    "                train_acc = accuracy_score(y_train_split, (train_pred >= 0.5).astype(int))\n",
    "                val_acc = accuracy_score(y_val, (val_pred >= 0.5).astype(int))\n",
    "            else:\n",
    "                # Perte hinge pour un classifieur linéaire de type SVM\n",
    "                decision_train = model.decision_function(X_train_split)\n",
    "                decision_val = model.decision_function(X_val)\n",
    "                train_loss = np.mean(np.maximum(0, 1 - y_train_split * decision_train))\n",
    "                val_loss = np.mean(np.maximum(0, 1 - y_val * decision_val))\n",
    "                train_acc = accuracy_score(y_train_split, train_pred)\n",
    "                val_acc = accuracy_score(y_val, val_pred)\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "    return history\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Construction des historiques pour différents modèles proxy\n",
    "# ---------------------------------------------------------------------\n",
    "all_models_history = {\n",
    "    'MLP': track_mlp_history(X_train_smote, y_train_smote),\n",
    "    'GRU-SVM': gru_model.history.history,  # historique Keras déjà calculé lors de l'entraînement du GRU\n",
    "    'L2-SVM': track_model_history(SGDClassifier, 'hinge', X_train_smote, y_train_smote),\n",
    "    'Softmax Regression': track_model_history(SGDClassifier, 'log_loss', X_train_smote, y_train_smote),\n",
    "    'Linear Regression': track_model_history(SGDRegressor, 'squared_error', X_train_smote, y_train_smote)\n",
    "}\n",
    "\n",
    "# Analyse simple des gaps train/validation pour détecter du surapprentissage\n",
    "for model_name, history in all_models_history.items():\n",
    "    if history['loss'] and history['val_loss']:\n",
    "        final_train_loss = history['loss'][-1]\n",
    "        final_val_loss = history['val_loss'][-1]\n",
    "        loss_gap = final_train_loss - final_val_loss\n",
    "        final_train_acc = history['accuracy'][-1]\n",
    "        final_val_acc = history['val_accuracy'][-1]\n",
    "        acc_gap = final_train_acc - final_val_acc\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  Loss Gap (Train - Val): {loss_gap:.4f}\")\n",
    "        print(f\"  Accuracy Gap (Train - Val): {acc_gap:.4f}\")\n",
    "        if loss_gap > 0.1 or acc_gap > 0.1:\n",
    "            print(\"  Possible overfitting detected.\")\n",
    "        else:\n",
    "            print(\"  No significant overfitting.\")\n",
    "        print()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Évaluation complémentaire des modèles proxy sur le jeu de test\n",
    "# (utile pour comparer leurs performances brutes)\n",
    "# ---------------------------------------------------------------------\n",
    "final_models = {\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(50, 50, 50), learning_rate_init=0.005, alpha=0.05, max_iter=1000, random_state=42),\n",
    "    'GRU-SVM': gru_svm_model,\n",
    "    'L2-SVM': SGDClassifier(loss='hinge', learning_rate='constant', eta0=1e-3, max_iter=1000, random_state=42),\n",
    "    'Softmax Regression': SGDClassifier(loss='log_loss', learning_rate='constant', eta0=1e-3, max_iter=1000, random_state=42),\n",
    "    'Linear Regression': SGDRegressor(loss='squared_error', learning_rate='constant', eta0=1e-3, max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in final_models.items():\n",
    "    if name == 'GRU-SVM':\n",
    "        # Pour GRU-SVM, on réutilise directement les prédictions déjà calculées\n",
    "        y_pred = gru_svm_y_test_pred\n",
    "        y_proba = gru_svm_y_test_proba\n",
    "    else:\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            y_proba = model.decision_function(X_test_scaled)\n",
    "        else:\n",
    "            y_proba = model.predict(X_test_scaled)\n",
    "            y_pred = (y_proba >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = {'AUC': auc, 'F1-Score': f1, 'Accuracy': acc}\n",
    "\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  AUC: {metrics['AUC']:.3f}\")\n",
    "    print(f\"  F1-Score: {metrics['F1-Score']:.3f}\")\n",
    "    print(f\"  Accuracy: {metrics['Accuracy']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11BaUHYH5klC"
   },
   "source": [
    "# 10. Conclusion\n",
    "\n",
    "The experimental results show that all investigated models achieve high performance on this breast cancer detection task, with accuracies above 90% and ROC–AUC values close to 1.0. Among them, the tuned logistic regression (Softmax classifier) provides the best overall trade-off between accuracy and ROC–AUC on the test set, while simpler linear and k-NN baselines remain highly competitive. The confusion matrices confirm that false negatives are rare for the best models, and the learning curves suggest that, apart from the GRU–SVM hybrid, there is no severe overfitting. Overall, these findings support the use of well-regularized linear or shallow non-linear models as strong, interpretable baselines for breast cancer diagnosis on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZrUU5Lg5laY",
    "outputId": "960aa9fa-7975-4d8e-b263-4c48c9df9346"
   },
   "outputs": [],
   "source": [
    "best_model = results_df['accuracy'].idxmax()\n",
    "best_accuracy = results_df.loc[best_model, 'accuracy']\n",
    "best_roc_auc = results_df.loc[best_model, 'roc_auc']\n",
    "\n",
    "print(f\"Meilleur Modèle : {best_model}\")\n",
    "print(f\"  Accuracy sur Test : {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"  ROC-AUC : {best_roc_auc:.4f}\")\n",
    "\n",
    "print(\"Tous les modèles ont dépassé le seuil de 90% d'accuracy :\")\n",
    "for model in results_df.index:\n",
    "    acc = results_df.loc[model, 'accuracy']\n",
    "    print(f\"  {model}: {acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vincent": {
   "sessionId": "1c8c86e14d5ab22785261b97_2025-12-06T19-13-39-515Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
